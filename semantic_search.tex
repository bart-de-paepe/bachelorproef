%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Semantic search}{Semantic search}}%
\label{ch:semantic_search}

%% TODO: In dit hoofstuk geef je een korte toelichting over hoe je te werk bent
%% gegaan. Verdeel je onderzoek in grote fasen, en licht in elke fase toe wat
%% de doelstelling was, welke deliverables daar uit gekomen zijn, en welke
%% onderzoeksmethoden je daarbij toegepast hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent.
%% 
%% Voorbeelden van zulke fasen zijn: literatuurstudie, opstellen van een
%% requirements-analyse, opstellen long-list (bij vergelijkende studie),
%% selectie van geschikte tools (bij vergelijkende studie, "short-list"),
%% opzetten testopstelling/PoC, uitvoeren testen en verzamelen
%% van resultaten, analyse van resultaten, ...
%%
%% !!!!! LET OP !!!!!
%%
%% Het is uitdrukkelijk NIET de bedoeling dat je het grootste deel van de corpus
%% van je bachelorproef in dit hoofstuk verwerkt! Dit hoofdstuk is eerder een
%% kort overzicht van je plan van aanpak.
%%
%% Maak voor elke fase (behalve het literatuuronderzoek) een NIEUW HOOFDSTUK aan
%% en geef het een gepaste titel.
\section{Inleiding}
Alle publicaties in IMIS moeten uniek zijn. Op basis van voorgaande stappen is dat met 100\% zekerheid te bepalen in het geval de DOI van de publicatie gevonden werd.
Als de DOI niet gevonden werd, kan er niet met zekerheid gesproken worden, maar kan er wel een score berekend worden die aangeeft wat de kans is dat de publicatie reeds in IMIS zit. Dat is mogelijk aan de hand van semantic search.\\
Op basis van de titel van het artikel wordt een embedding berekend. Vervolgens wordt die vergeleken met alle embeddings van de titels in IMIS om zo tot een score te komen van de gelijkenis tussen beide. Dit wordt voorgesteld in figuur \ref{fig:Semanticsearch}.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{./5_semantic_search/embeddings.jpg}
    \caption[Semantic search.]{\label{fig:Semanticsearch}Semantic search overzicht.}
\end{figure}
\\
Indien de score hoog is dan is er een grote waarschijnlijkheid dat de publicatie reeds in IMIS zit. In het geval van een lage score is de waarschijnlijkheid eerder klein.\\
Embeddings worden opgeslagen in een vector databank. Er zijn talloze producten beschikbaar:
\begin{itemize}
    \item Pinecone
    \item Chroma
    \item Weaviate
    \item Qdrant
    \item Milvus
    \item Vespa
    \item SingleStore
    \item Redis
    \item Elastic Stack
    \item Mongo
    \item …
    \item (Elke database die een n-array van cijfers kan opslaan)
\end{itemize}

\section{Chroma}
Chroma \autocite{Chroma2025} is een gebruiksvriendelijke vector database die toelaat om semantic search lokaal te testen zonder extra kosten, zonder account, en zonder installatie van andere software.\\
Het online artikel \textcite{Usechroma2025} beschrijft stap voor stap hoe een semantic search met Chroma uitgevoerd kan worden. 
De code op github \textcite{Depaepechroma2025} maakt hiervan een implementatie aangepast voor de Google Scholar alerts.
De connectie met de Chroma database is te zien in codefragment \ref{code:Chromadb}.
\begin{listing}
    \begin{minted}{python}
        ...
        chroma_client = chromadb.Client()
        # https://docs.trychroma.com/docs/collections/configure
        self.collection = chroma_client.create_collection(
            name="my_collection",
            metadata={
                "hnsw:space": "cosine"
            }
        )
        ...
    \end{minted}
    \caption[Connect Chroma]{Connecteren met Chroma.}
    \label{code:Chromadb}
\end{listing}
Vervolgens worden alle titels uit IMIS opgevraagd en worden de overeenkomstige embeddings berekend aan de hand van de code in codefragment \ref{code:Chromaembeddings}.
\begin{listing}
    \begin{minted}{python}
        def initialize_embeddings(self):
            result = requests.get(``https://www.vliz.be/nl/
            imis?count=2000&module=ref&searchspcollist=39&show=json'')
            publications = result.json()
            documents = []
            ids = []
            count = 1
            for publication in publications:
            #self.logging_service.logger.debug(publication)
                documents.append(publication['StandardTitle'])
                ids.append(f"id{count}")
                count+=1
        
            self.collection.add(
                documents=documents,
                ids=ids
            )
    \end{minted}
    \caption[Chroma embeddings]{Berekenen van de embeddings.}
    \label{code:Chromaembeddings}
\end{listing}
Dan kan een titel opgezocht worden zoals getoond wordt in codefragment \ref{code:Chromaquery}.
\begin{listing}
    \begin{minted}{python}
        def do_semantic_search(self, title):
            results = self.collection.query(
                query_texts=[title],  # Chroma will embed this for you
                n_results=2  # how many results to return
            )
            return results['distances'][0][0]
    \end{minted}
    \caption[Query Chroma]{Opzoeken van een titel.}
    \label{code:Chromaquery}
\end{listing}
\\
De test was succesvol. Bij wijze van proef werd de titel van één van de zoekresultaten toegevoegd aan de lijst van titels uit IMIS. Het resultaat is te zien in figuur \ref{fig:Chroma}.
\begin{figure}
    \centering
    \includegraphics[width=1.0\textwidth]{./5_semantic_search/chroma-cosine-score.jpg}
    \caption[Chroma resultaat.]{\label{fig:Chroma}Chroma resultaat.}
\end{figure}
Deze oplossing voegt Chroma toe als database naast MongoDB die nodig is voor de Web scraping. Het zou beter zijn indien de embeddings ook in MongoDB opgeslagen kunnen worden. Dat wordt verder onderzocht.
\section{MongoDB Atlas}
Atlas Vector Search \autocite{Mongodbvectorsearch2025} laat toe om de embeddings tezamen op te slaan met de originele data waar ze van afgeleid zijn.\\
De online documentatie \textcite{Usemongodbvectorsearch2025} beschrijft stap voor stap hoe een semantic search met Atlas Vector Search lokaal uitgevoerd kan worden. 
De code op github \textcite{Depaepemongodb2025} maakt hiervan een implementatie aangepast voor de Google Scholar alerts.
De selectie van het model voor de embeddings is te zien in codefragment \ref{code:Mongodbmodel}.
\begin{listing}
    \begin{minted}{python}
        ...
        self.model = SentenceTransformer("nomic-ai/nomic-embed-text-v1", trust_remote_code=True)
        ...
    \end{minted}
    \caption[MongoDB set model]{Configureren van het model met MongoDB.}
    \label{code:Mongodbmodel}
\end{listing}
Vervolgens worden alle titels uit IMIS opgevraagd en worden de overeenkomstige embeddings berekend aan de hand van de code in codefragment \ref{code:Mongodbembeddings}.
\begin{listing}
    \begin{minted}{python}
        def initialize_embeddings(self):
            docs = []
            data = []
            embeddings = []
            result = requests.get(IMIS)
            publications = result.json()
            for publication in publications:
                data.append(publication['StandardTitle'])
                embeddings.append(self.get_embedding(publication['StandardTitle']))
        
            for i, (embedding, title) in enumerate(zip(embeddings, data)):
            doc = {
                "_id": i,
                "title": title,
                "embedding": embedding,
            }
            docs.append(doc)
            self.db_service.set_collection("embeddings")
            self.db_service.insert_many(docs)
    \end{minted}
    \caption[MongoDB embeddings]{Berekenen van de embeddings.}
    \label{code:Mongodbembeddings}
\end{listing}
Vervolgens wordt de lijst met embeddings geïndexeerd zoals getoond wordt in codefragment \ref{code:Mongodbindex}.
\begin{listing}
    \begin{minted}{python}
        def create_search_index(self):
            search_index_model = SearchIndexModel(
            definition={
                "fields": [
                {
                    "type": "vector",
                    "path": "embedding",
                    "similarity": "dotProduct",
                    "numDimensions": 768
                }
                ]
            },
            name="vector_index",
            type="vectorSearch"
            )
            self.db_service.set_collection("embeddings")
            self.db_service.create_search_index(model=search_index_model)
    \end{minted}
    \caption[MongoDB calculate index]{Indexeren van de embeddings.}
    \label{code:Mongodbindex}
\end{listing}
Dan kan een titel opgezocht worden zoals getoond wordt in codefragment \ref{code:Mongodbquery}.
\begin{listing}
    \begin{minted}{python}
        def do_semantic_search(self, title):
            query_embedding = self.get_embedding(title)
            pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "queryVector": query_embedding,
                    "path": "embedding",
                    "exact": True,
                    "limit": 5
                }
            },
            {
                "$project": {
                    "_id": 0,
                    "title": 1,
                    "score": {
                        "$meta": "vectorSearchScore"
                    }
                }
            }
            ]
            self.db_service.set_collection("embeddings")
            result = self.db_service.aggregate(pipeline)
    \end{minted}
    \caption[MongoDB query]{Opzoeken van een titel.}
    \label{code:Mongodbquery}
\end{listing}
\\
De test was succesvol. Bij wijze van proef werd de titel van één van de zoekresultaten toegevoegd aan de lijst van titels uit IMIS. Het resultaat is te zien in figuur \ref{fig:Mongodb}.
\begin{figure}
    \centering
    \includegraphics[width=1.0\textwidth]{./5_semantic_search/mongodb-cosine-score.jpg}
    \caption[Mongodb resultaat.]{\label{fig:Mongodb}Mongodb resultaat.}
\end{figure}
Deze oplossing breidt de bestaande MongoDB databank uit met embeddings. Voor artikels zonder indentifcatie kan een score berekend worden die duidt op duplicaten in IMIS. 

%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Natural Language Processing}{Natural Language Processing}}%
\label{ch:natural_language_processing}

%% TODO: In dit hoofstuk geef je een korte toelichting over hoe je te werk bent
%% gegaan. Verdeel je onderzoek in grote fasen, en licht in elke fase toe wat
%% de doelstelling was, welke deliverables daar uit gekomen zijn, en welke
%% onderzoeksmethoden je daarbij toegepast hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent.
%% 
%% Voorbeelden van zulke fasen zijn: literatuurstudie, opstellen van een
%% requirements-analyse, opstellen long-list (bij vergelijkende studie),
%% selectie van geschikte tools (bij vergelijkende studie, "short-list"),
%% opzetten testopstelling/PoC, uitvoeren testen en verzamelen
%% van resultaten, analyse van resultaten, ...
%%
%% !!!!! LET OP !!!!!
%%
%% Het is uitdrukkelijk NIET de bedoeling dat je het grootste deel van de corpus
%% van je bachelorproef in dit hoofstuk verwerkt! Dit hoofdstuk is eerder een
%% kort overzicht van je plan van aanpak.
%%
%% Maak voor elke fase (behalve het literatuuronderzoek) een NIEUW HOOFDSTUK aan
%% en geef het een gepaste titel.
\section{Inleiding}
Na de web scraping zijn de gegevens van elk zoekresultaat gestructureerd opgeslagen. Per definitie zijn al deze resultaten relevant voor IMIS want Google Scholar (GS) heeft ze opgezocht in functie van de zoekopdracht. De sortering van de zoekresultaten gebeurt op basis van de omvang van de integrale tekst, het aanzien van het tijdschrift en van de auteurs en het aantal citaties (inclusief de gedateerdheid ervan). Op die manier volgt GS de manier van werken binnen de academische wereld.\\
Maar daarnaast is het nog steeds mogelijk om voor elk zoekresultaat een score af te leiden die aangeeft hoe relevant de publicatie is voor de zoekopdracht aan de hand van de frequentie van elke zoekterm in de tekst. Algemeen wordt aangenomen dat hoe meer een zoekterm voorkomt in de tekst, des te relevanter die tekst zal zijn.\\
Daar bestaan Natural Language Processing (NLP) technieken voor. NLP is een verzamelnaam van een hele groep toepassingen en algoritmes die tekst omzetten in informatie. Deze zijn zeer divers en daarom ook onderverdeeld in verschillende deelgebieden. Het bepalen van de relevantie van een tekst in functie van een trefwoord valt eerder onder het deelgebied van de ``Natural Language Understanding'' die alle technieken bundelt die toelaten om de betekenis van een tekst beter te begrijpen.\\

\section{Relevantiescore}
Het uitgangspunt is om een score te berekenen door te tellen hoe vaak een trefwoord voorkomt in de tekst. De frequentie is dan recht evenredig met de relevantie van die tekst. Een eenvoudige techniek voor het bepalen van de frequentie is aan de hand van een ``Bag of Words'' (BoW). Dat is een tabel met een rij voor elke tekst en een kolom voor elk uniek woord. De cellen tonen het aantal keer dat het woord voorkomt in de tekst.  Dit is te zien in figuur \ref{fig:bow}.
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{./4_NLP/bow.jpg}
    \caption[Bag of Words.]{\label{fig:bow}Bag of Words.}
\end{figure}
Toch is de frequentie op zich nog niet de beste waardemeter voor een tekst. Er kunnen namelijk woorden heel vaak voorkomen die op zich weinig vertellen over het onderwerp. Om daaraan tegemoet te komen bestaat er een variant van de BoW, die in plaats van gewoon te tellen de ``term frequency-inverse document frequency'' (Tf-Idf) geeft. De score is dan ook omgekeerd evenredig met de frequentie van de zoekterm in alle documenten. De formules om de Tf-Idf te berekenen, zijn te zien in codefragment \ref{code:tf-idf} en het resultaat in figuur \ref{fig:tf-idf}.
\begin{listing}[h!]
    \[
        score\ =\ tf\ \ast\ idf
    \]  
    where
    \[
        tf=term\ frequency\ \left(see\ above\right)
    \] 
    
    \[
        idf_t=log\left(\frac{N}{df_t}\right)
    \]  
    
    \[ 
        N=total\ number\ ofdocuments
    \]  
    
    \[ 
        df_t=the\ number\ of\ documents\ in\ which\ term\ t\ occurs
    \] 
     
    \caption[term frequency-inverse document frequency]{Berekening van de term frequency-inverse document frequency.}
    \label{code:tf-idf}
\end{listing}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{./4_NLP/tf-idf.jpg}
    \caption[term frequency-inverse document frequency.]{\label{fig:tf-idf}Term frequency-inverse document frequency.}
\end{figure}
De Tf-Idf methode is de de facto berekening van de relevantie van een term voor een bepaalde tekst. De \[TFidVectorizer()\] \footnote{https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html} van Scikit-Learn is een praktische tool om de Tf-Idf score van elk afzonderlijk woord in een tekst te berekenen. De code op github \textcite{Depaepenlp2025} maakt hiervan een implementatie aangepast voor de GS alerts.
\section{Tekstverwerking}
De BoW geeft wel aanleiding tot tabellen met zeer grote dimensies. Hoe meer teksten er zijn, des te uitgebreider zal de woordenschat worden. Daarom wordt de BoW altijd voorafgegaan door tekstverwerking die stopwoorden \footnote{Stopwoorden (of, a, the, in ,you, ...) komen vaak voor maar hebben geen toegevoegde waarde over het onderwerp.} verwijdert en lemmatisering \footnote{Lemmatisering zet woorden om naar hun basisvorm, maar houdt daarbij rekening met de context. Voorbeeld ``caring'' wordt omgezet in ``care'' en niet in ``car''.}.\\
De voornaamwoorden in de tekst worden vervangen door het trefwoord waarnaar ze verwijzen (vb. tabel \ref{table:nlp}).
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|} 
        \hline
        voor&``Het VLIZ is pionier in zeekennis.\\&Het heeft de Simon Stevin als onderzoeksvaartuig.\\&Daarmee voert het marien onderzoek uit.''\\
        \hline
        na&``Het VLIZ is pionier in zeekennis.\\&Het VLIZ heeft de Simon Stevin als onderzoeksvaartuig.\\&Simon Stevin als onderzoeksvaartuig voert het VLIZ marien onderzoek uit.''\\
        \hline
    \end{tabular}
    \caption{Voor en na coreference resolution.}
    \label{table:nlp}
\end{table}
Het opzoeken van de paren (voornaamwoord - zelfstandig naamwoord) aan de hand van de Spacy Coreference resolver \autocite{Spacy2025} is te zien in codefragment \ref{code:coreference} en is eveneens ge√Ømplementeerd in \textcite{Depaepenlp2025}.\\
\begin{listing}
    \begin{minted}{python}
        import spacy
        ...
        def __init__(self, db_service: DBService, logging_service: LoggingService):
            self.db_service = db_service
            self.logging_service = logging_service
            self.nlp = spacy.load("en_coreference_web_trf")
        ...
        def coreference_resolution(self, text):
            doc = self.nlp(text)
            spans = doc.spans
            span_array = []
            for spangroup in spans.values():
                span_tuple = []
                for span in spangroup:
                    span_tuple.append(text[span.start_char:span.end_char])
                    span_array.append(span_tuple)
            return span_array
    \end{minted}
    \caption[Coreference resolver]{Coreference resolver}
    \label{code:coreference}
\end{listing}
Na NLP is de tweede onderzoeksdoelstelling bereikt: Een proof-of-concept van het proces dat een score voor elk zoekresultaat berekent.
%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Natural Language Processing}{Natural Language Processing}}%
\label{ch:natural_language_processing}

%% TODO: In dit hoofstuk geef je een korte toelichting over hoe je te werk bent
%% gegaan. Verdeel je onderzoek in grote fasen, en licht in elke fase toe wat
%% de doelstelling was, welke deliverables daar uit gekomen zijn, en welke
%% onderzoeksmethoden je daarbij toegepast hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent.
%% 
%% Voorbeelden van zulke fasen zijn: literatuurstudie, opstellen van een
%% requirements-analyse, opstellen long-list (bij vergelijkende studie),
%% selectie van geschikte tools (bij vergelijkende studie, "short-list"),
%% opzetten testopstelling/PoC, uitvoeren testen en verzamelen
%% van resultaten, analyse van resultaten, ...
%%
%% !!!!! LET OP !!!!!
%%
%% Het is uitdrukkelijk NIET de bedoeling dat je het grootste deel van de corpus
%% van je bachelorproef in dit hoofstuk verwerkt! Dit hoofdstuk is eerder een
%% kort overzicht van je plan van aanpak.
%%
%% Maak voor elke fase (behalve het literatuuronderzoek) een NIEUW HOOFDSTUK aan
%% en geef het een gepaste titel.
\section{Inleiding}
Google Scholar (GS) heeft feitelijk al gezocht naar publicaties die relevant zijn voor onze zoekopdracht. De sortering van de zoekresultaten gebeurt op basis van de omvang van de integrale tekst, het aanzien van het tijdschrift en van de auteurs en het aantal citaties (inclusief de gedateerdheid ervan). Op die manier volgt GS de manier van werken binnen de academische wereld.\\
Maar dit laat nog steeds ruimte om voor elk zoekresultaat een score af te leiden die aangeeft hoe relevant de publicatie is voor IMIS. De zoekopdracht voor het VLIZ bijvoorbeeld gebruikt als één van de trefwoorden ``Simon Stevin'', zijnde het wetenschappelijk vaartuig van het VLIZ. Dat betekent dat GS ook zoekresultaten zal geven van publicaties die verwijzen naar ``Simon Stevin'', de Vlaamse geleerde uit de 16de eeuw. Het is interessant om die artikels te kunnen markeren met een lagere score ten opzichte van publicaties die het trefwoord ``VLIZ'' bevatten.\\
Daar bestaan Natural Language Processing (NLP) technieken voor. NLP is een verzamelnaam van een hele groep toepassingen en algoritmes die tekst omzetten in informatie. Deze zijn zeer divers en daarom ook onderverdeeld in verschillende deelgebieden. Het bepalen van de relevantie van een tekst in functie van een trefwoord valt eerder onder het deelgebied van de ``Natural Language Understanding''.\\

\section{Relevantiescore}
Het uitgangspunt is om een score te berekenen door te tellen hoe vaak een trefwoord voorkomt in de tekst. De frequentie is dan recht evenredig met de relevantie van die tekst. Een eenvoudige techniek voor het bepalen van de frequentie is aan de hand van een ``Bag of Words'' (BoW). Dat is een tabel met een rij voor elke tekst en een kolom voor elk uniek woord. De cellen tonen het aantal keer dat het woord voorkomt in de tekst.  Dit is te zien in figuur \ref{fig:bow}.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{./4_NLP/bow.jpg}
    \caption[Bag of Words.]{\label{fig:bow}Bag of Words.}
\end{figure}
Toch is de frequentie op zich nog niet de beste waardemeter voor een tekst. Er kunnen namelijk woorden heel vaak voorkomen die op zich weinig vertellen over het onderwerp. Om daaraan tegemoet te komen bestaat er een variant van de BoW, die in plaats van gewoon te tellen de ``term frequency-inverse document frequency'' (Tf-Idf) geeft. De formules zijn te zien in codefragment \ref{code:tf-idf} en het resultaat in figuur \ref{fig:tf-idf}.
\begin{listing}
    \begin{equation}
        score\ =\ tf\ \ast\ idf
    \end{equation}  
    where
    \begin{equation}
        tf=term\ frequency\ \left(see\ above\right)
    \end{equation} 
    
    \begin{equation}
        idf_t=log\left(\frac{N}{df_t}\right)
    \end{equation}  
    
    \begin{equation} 
        N=total\ number\ ofdocuments
    \end{equation}  
    
    \begin{equation} 
        df_t=the\ number\ of\ documents\ in\ which\ term\ t\ occurs
    \end{equation} 
     
    \caption[term frequency-inverse document frequency]{term frequency-inverse document frequency}
    \label{code:tf-idf}
\end{listing}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{./4_NLP/tf-idf.jpg}
    \caption[term frequency-inverse document frequency.]{\label{fig:tf-idf}term frequency-inverse document frequency.}
\end{figure}
Maar de relevantie van een publicatie kan niet afhangen van het aantal zoekresultaten, daarom valt de ``inverse document frequency'' weg. In de plaats zijn er andere parameters om de relevantie te benaderen.
\begin{itemize}
    \item De topic-sentence ratio: een ratio van het trefwoord count ten opzichte van het totaal aantal zinnen.
    \item De topic-noun ratio: een ratio van het trefwoord count ten opzichte van het totaal aantal zelfstandige naamwoorden.
\end{itemize}
Aan de hand van die parameters kan een relevantiescore berekend worden zoals te zien in codefragment \ref{code:relevantiescore}.
\begin{listing}
    \begin{equation}
        score=topic count\ \ast\ log\left(topic-sentence ratio\right)\ \ast\ log\left(topic-noun ratio\right)
    \end{equation}  
    \caption[relevantiescore]{relevantiescore}
    \label{code:relevantiescore}
\end{listing}
De code op github \textcite{Depaepenlp2025} maakt hiervan een implementatie aangepast voor de GS alerts.
\section{Tekstverwerking}
De BoW geeft wel aanleiding tot tabellen met zeer grote dimensies. Hoe meer teksten er zijn, des te uitgebreider zal de woordenschat worden. Daarom wordt de BoW altijd voorafgegaan door tekstverwerking die stopwoorden \footnote{Stopwoorden (of, a, the, in ,you, ...) komen vaak voor maar hebben geen toegevoegde waarde over het onderwerp.} verwijdert en lemmatisering \footnote{Lemmatisering zet woorden om naar hun basisvorm, maar houdt daarbij rekening met de context. Voorbeeld ``caring'' wordt omgezet in ``care'' en niet in ``car''.}.\\
Voornaamwoorden kunnen verwijzen naar het trefwoord 
(vb. tabel \ref{table:nlp}).
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|} 
        \hline
        voor&``Het VLIZ is pionier in zeekennis.\\&Het heeft de Simon Stevin als onderzoeksvaartuig.\\&Daarmee voert het marien onderzoek uit.''\\
        \hline
        na&``Het VLIZ is pionier in zeekennis.\\&Het VLIZ heeft de Simon Stevin als onderzoeksvaartuig.\\&Simon Stevin als onderzoeksvaartuig voert het VLIZ marien onderzoek uit.''\\
        \hline
    \end{tabular}
    \caption{Voor en na coreference.}
    \label{table:nlp}
\end{table}
Het is dus interessant om ze te vervangen door het trefwoord zelf zodat ze mee een invloed hebben op de score. ``Coreference resolution'' is daar de geschikte NLP techniek voor. In een eerste fase worden alle gerelateerde voornaamwoorden en zelfstandige naamwoorden opgezocht. In een tweede fase worden alle gevonden voornaamwoorden vervangen door hun bijhorende zelfstandig naamwoord. Daarvoor gebruikt deze techniek een coreference model dat bestaat uit opeenvolgende paren van tokens met een bijhorende coreference score.
Het opzoeken van paren is te zien in codefragment \ref{code:coreference}.
\begin{listing}
    \begin{minted}{python}
        import spacy
        ...
        def __init__(self, db_service: DBService, logging_service: LoggingService):
            self.db_service = db_service
            self.logging_service = logging_service
            self.nlp = spacy.load("en_coreference_web_trf")
        ...
        def coreference_resolution(self, text):
            doc = self.nlp(text)
            spans = doc.spans
            span_array = []
            self.logging_service.logger.debug(spans)
            for spangroup in spans.values():
                span_tuple = []
                for span in spangroup:
                    self.logging_service.logger.debug(text[span.start_char:span.end_char])
                    span_tuple.append(text[span.start_char:span.end_char])
                    span_array.append(span_tuple)
            return span_array
    \end{minted}
    \caption[Coreference resolver]{Coreference resolver}
    \label{code:coreference}
\end{listing}
